{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e070c3ef-b027-4fab-9ecc-14f455654a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from langchain.chains import StuffDocumentsChain, RetrievalQA, LLMChain, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chat_models.base import BaseChatModel\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings, OllamaEmbeddings\n",
    "from langchain.llms import Ollama, BaseLLM\n",
    "from langchain.llms.base import LLM\n",
    "from langchain.schema import ChatResult, ChatGeneration\n",
    "from langchain.schema import Document, Generation, LLMResult\n",
    "from langchain.schema.messages import AIMessage, HumanMessage\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.llms import OpenAI\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain.schema import OutputParserException\n",
    "from pathlib import Path\n",
    "from pydantic import BaseModel, Field\n",
    "from tqdm import tqdm\n",
    "from typing import List, Optional, Any\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "MODEL=\"llama3.3\"\n",
    "API_URL=\"http://127.0.0.1:11434\"\n",
    "FILE=\"echantillon_1000_hs_2024_TOC.parquet\"\n",
    "QUESTIONS=[\"De combien est le contingent annuel d'heures supplémentaires ?\",\n",
    "           \"Quels sont les taux de majorations des heures supplémentaires ?\" ,\n",
    "           \"Quel est le taux pour la contrepartie obligatoire en repos ?\",\n",
    "           \"Quel est le taux pour le repos compensateur de remplacement ?\",\n",
    "          \"Quel est le délai de prévenance pour les heures supplémentaires ?\"]\n",
    "\n",
    "OUTPUT_DIR_RESULTS=\"results\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba1cf34-d198-4640-939a-4c5eba6baaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatOllama(BaseChatModel):\n",
    "    model: str = MODEL\n",
    "    base_url: str = \"http://localhost:11434\"\n",
    "    \n",
    "    def _generate(self, messages: List[HumanMessage], stop: Optional[List[str]] = None, **kwargs) -> ChatResult:\n",
    "        # Combine the messages into a single prompt\n",
    "        prompt = \"\\n\".join([f\"{msg.content}\" for msg in messages])\n",
    "        response = requests.post(\n",
    "            f\"{self.base_url}/api/chat\",\n",
    "            json={\"model\": self.model,\n",
    "  \"temperature\": 0, \"messages\": [{\"role\": \"user\", \"content\": prompt}], \"stream\": False},\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        content = response.json()[\"message\"][\"content\"]\n",
    "        return ChatResult(generations=[ChatGeneration(message=AIMessage(content=content))])\n",
    "    \n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"ollama-chat\"\n",
    "\n",
    "llm = ChatOllama(api_url=API_URL)\n",
    "\n",
    "class DonneesAccordsHeuresSupp(BaseModel):\n",
    "    \"\"\"Données structurées des accords d'heures supp\"\"\"\n",
    "    index: Optional[str] = Field(default=None, description=\"Unique index\")\n",
    "    base_legale_hebdomadaire: Optional[int] = Field(\n",
    "        default=None, description=\"Base légale hebdomadaire, 35 heures\"\n",
    "    )    \n",
    "    duree_annuel_heures: Optional[int] = Field(\n",
    "        default=None, description=\"Durée annuelle d'heures de travail, 1607 heures\"\n",
    "    )    \n",
    "    contingent_annuel_heures_supplementaires: Optional[int] = Field(\n",
    "        default=None, description=\"Nombre d'heures au contingent annuel d'heures supplémentaires\"\n",
    "    )\n",
    "    nombre_taux_majoration_differents: Optional[int] = Field(\n",
    "        default=None, description=\"Nombre de taux de majoration différents des heures supplémentaires en heures supplémentaires payées (hors contrepartie obligatoire en repos et repos compensateur de remplacement)\"\n",
    "    )\n",
    "    premier_taux_majoration: Optional[int] = Field(\n",
    "        default=None, description=\"Premier taux de majoration\"\n",
    "    )\n",
    "    plage_premier_taux_majoration: Optional[str] = Field(\n",
    "        default=None, description=\"Plage des heures du premier taux de majoration\"\n",
    "    )\n",
    "    deuxieme_taux_majoration: Optional[int] = Field(\n",
    "        default=None, description=\"Deuxième taux de majoration\"\n",
    "    )\n",
    "\n",
    "    plage_deuxieme_taux_majoration: Optional[str] = Field(\n",
    "        default=None, description=\"Plage des heures du deuxième taux de majoration\"\n",
    "    )\n",
    "    troisieme_taux_majoration: Optional[int] = Field(\n",
    "        default=None, description=\"Troisième taux de majoration\"\n",
    "    )\n",
    "    plage_troisieme_taux_majoration: Optional[str] = Field(\n",
    "        default=None, description=\"Plage des heures du troisième taux de majoration\"\n",
    "    )\n",
    "    presence_repos_compensateur_remplacement: Optional[bool] = Field(\n",
    "        default=None, description=\"Mention à un repos compensateur de remplacement (RCR)\"\n",
    "    )\n",
    "    taux_majoration_contrepartie_obligatoire_en_repos: Optional[int] = Field(\n",
    "        default=None, description=\"Taux de majoration de la contrepartie obligatoire en repos (COR)\"\n",
    "    )\n",
    "    delai_prevenance: Optional[str] = Field(\n",
    "        default=None, description=\"Délai de prévenance des heures supplémentaires\"\n",
    "    )\n",
    "    \n",
    "    \n",
    "parser = PydanticOutputParser(pydantic_object=DonneesAccordsHeuresSupp)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            (\n",
    "                \"You are an expert in extracting structured data.\\n\"\n",
    "                \"You MUST return only a JSON object in this exact format:\\n\\n\"\n",
    "                \"{format_instructions}\\n\\n\"\n",
    "                \"Do not include any other fields or text. No explanations. No markdown. Just valid JSON.\"\n",
    "            ),\n",
    "        ),\n",
    "        (\"human\", \"{query}\"),\n",
    "    ]\n",
    ").partial(format_instructions=parser.get_format_instructions())\n",
    "\n",
    "\n",
    "intermediate_chain = prompt | llm\n",
    "\n",
    "    \n",
    "embedder = HuggingFaceEmbeddings(model_name=\"BAAI/bge-m3\")\n",
    "vector_store = Chroma(embedding_function=embedder, persist_directory=\"./chroma_db\")\n",
    "\n",
    "\n",
    "df=pd.read_parquet(FILE)\n",
    "df=df.set_index(\"numdossier_new\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c5054a7d-0a61-4d5c-9200-243f500ac389",
   "metadata": {},
   "source": [
    "query = \"\"\"\n",
    "Quelles sont les données de l'accord suivant ? \n",
    "\n",
    "Pour les 4 premières heures (36ème à 39ème heure) : 20 % ;\n",
    "Pour les 3 heures suivantes (40ème à 43ème heure) : 30 % ;\n",
    "À partir de la 44ème heure : 50 %.\n",
    "[...] le contingent annuel d’heures supplémentaires est fixé à 250 heures par salarié.\n",
    "Les heures supplémentaires effectuées et comptabilisées [...] sont compensées, avec leur majoration, pour moitié en heures supplémentaires payées et pour moitié par du repos compensateur.\n",
    "4 heures supplémentaires =  droit à 2 x 1,20 = 2,4 heures de repos compensateur de remplacement, l’autre moitié des heures supplémentaires effectuées étant rémunérée, avec la majoration applicable.\n",
    "\n",
    "\"\"\"\n",
    "chain.invoke({\"query\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6879fa-824e-4cac-abf0-ed00b7261820",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG=False\n",
    "\n",
    "Path(OUTPUT_DIR_RESULTS).mkdir(parents=True, exist_ok=True)\n",
    "data=[]\n",
    "for index, row in df.iterrows():\n",
    "    retriever=vector_store.as_retriever(\n",
    "        search_kwargs={\n",
    "                \"k\": 2, \n",
    "                \"filter\": {'index': index}\n",
    "            }\n",
    "        )\n",
    "\n",
    "    docs=[]\n",
    "    for question in QUESTIONS:\n",
    "        docs+= retriever.invoke(question)\n",
    "    context=\"\\n\".join({d.page_content for d in docs})\n",
    "    \n",
    "    query = f\"\"\"\n",
    "    Quelles sont les données de l'accord suivant ? \n",
    "\n",
    "    ### Données\n",
    "    \n",
    "    index={index}\n",
    "    {context}\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    raw_output = intermediate_chain.invoke({\"query\": query})\n",
    "    try:\n",
    "        donnees_accords = parser.parse(raw_output.content)\n",
    "        #print(\"Parsed output:\", donnees_accords)\n",
    "    except OutputParserException as e:\n",
    "        donnees_accords = DonneesAccordsHeuresSupp()\n",
    "        print(\"Index:\\n\", index)\n",
    "        if DEBUG:\n",
    "            print(\"Raw LLM output:\\n\", raw_output)\n",
    "            print(\"Parsing failed:\", e)\n",
    "        \n",
    "    try:\n",
    "        donnees_accords.index=index\n",
    "        with open(f\"{OUTPUT_DIR_RESULTS}/heures_supp_{index}.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(donnees_accords.model_dump(), f, indent=2, ensure_ascii=False)\n",
    "        data.append(donnees_accords)\n",
    "    except:\n",
    "        print(f\"problème avec {index}\")\n",
    "df = pd.DataFrame([item.dict() for item in data])\n",
    "df.to_parquet(\"results_heures_supp.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (uv)",
   "language": "python",
   "name": "my-uv-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
